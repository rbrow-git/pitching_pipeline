{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import asyncio\n",
    "import os\n",
    "import sqlite3\n",
    "from io import StringIO\n",
    "\n",
    "# Third-party imports\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from scrapling import StealthyFetcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scrape one year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_year(player_id, year):\n",
    "    # The URL pattern for pitching game logs\n",
    "    url = f\"https://www.baseball-reference.com/players/gl.fcgi?id={player_id}&t=p&year={year}\"\n",
    "    page = await StealthyFetcher().async_fetch(url)  # the async version of fetch\n",
    "    soup = BeautifulSoup(page.html_content, 'html.parser')\n",
    "    #extract the player name from the title\n",
    "    player_name = ' '.join(soup.find('title').text.split()[:2]) if soup.find('title') else None\n",
    "    game_log_table = soup.find('table', id='pitching_gamelogs')\n",
    "    df = pd.read_html(StringIO(str(game_log_table)))[0] if game_log_table else []\n",
    "    if not isinstance(df, list) and not df.empty:\n",
    "        df['year'] = year\n",
    "        df['player_id'] = player_id\n",
    "        df['name'] = player_name\n",
    "    return df, player_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scrape all years for 1 guy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def player_scrape(player_id):\n",
    "    \"\"\"Scrape and combine pitching data for 2021-2024 for a player.\"\"\"\n",
    "    years = [2021, 2022, 2023, 2024]  # Fixed years to scrape\n",
    "    tasks = [scrape_year(player_id, year) for year in years] # run all the years at once\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    # Combine dataframes, filtering out empty ones\n",
    "    dfs = [df for df, _ in results if not isinstance(df, list) and not df.empty]\n",
    "    combined_df = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse_pitcher_game_logs(df):\n",
    "    rename_map = {\n",
    "        'Rk': 'season_game_num',\n",
    "        'Gcar': 'career_game_num',\n",
    "        'Gtm': 'team_game_num',\n",
    "        'Date': 'date',\n",
    "        'Tm': 'team_id',\n",
    "        'Unnamed: 5': 'road_indicator',\n",
    "        'Opp': 'opp_id',\n",
    "        'Rslt': 'game_result',\n",
    "        'Inngs': 'innings',\n",
    "        'DR': 'days_rest',\n",
    "        'IP': 'ip',\n",
    "        'H': 'h',\n",
    "        'R': 'r',\n",
    "        'ER': 'er',\n",
    "        'BB': 'bb',\n",
    "        'SO': 'so',\n",
    "        'HR': 'hr',\n",
    "        'HBP': 'hbp',\n",
    "        'ERA': 'era',\n",
    "        'FIP': 'fip',\n",
    "        'BF': 'batters_faced',\n",
    "        'Pit': 'pitches',\n",
    "        'Str': 'strikes_total',\n",
    "        'StL': 'strikes_looking',\n",
    "        'StS': 'strikes_swinging',\n",
    "        'GB': 'ground_balls',\n",
    "        'FB': 'flyballs',\n",
    "        'LD': 'line_drives',\n",
    "        'PU': 'pop_ups',\n",
    "        'GSc': 'game_score',\n",
    "        'SB': 'sb',\n",
    "        'CS': 'cs',\n",
    "        'PO': 'pickoffs',\n",
    "        'AB': 'ab',\n",
    "        '2B': '2b',\n",
    "        '3B': '3b',\n",
    "        'IBB': 'ibb',\n",
    "        'GDP': 'gidp',\n",
    "        'SF': 'sf',\n",
    "        'ROE': 'roe',\n",
    "        'aLI': 'avg_leverage_index',\n",
    "        'WPA': 'win_prob_added',\n",
    "        'acLI': 'adjusted_cli_avg',\n",
    "        'cWPA': 'champ_win_prob_added',\n",
    "        'RE24': 'base_out_run_saved'\n",
    "    }\n",
    "    #drop un needed and apply column mapping\n",
    "    df = df.drop(columns=['Dec','IR','IS','Unk','DFS(DK)','DFS(FD)', 'Entered', 'Exited','Rslt','Inngs'], \n",
    "                                    errors='ignore').rename(columns=rename_map)\n",
    "    # Convert road_indicator to dummy variables and filter invalid team_id rows\n",
    "    df = pd.concat([df.drop('road_indicator', axis=1), \n",
    "                            pd.get_dummies(df['road_indicator'], prefix='road')], axis=1)\n",
    "    df = df[~((df['team_id'].isna()) | (df['team_id'] == \"Tm\"))]\n",
    "    # Ensure player_id, name, and year are first three columns\n",
    "    desired_order = ['player_id', 'name', 'year'] + [col for col in df.columns if col not in ['player_id', 'name', 'year']]\n",
    "    df = df[desired_order]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pitcher_logs(df, db_path=\"baseball.db\"):\n",
    "    db_path = os.path.abspath(db_path)\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(db_path) or '.', exist_ok=True)\n",
    "    # Create connection to SQLite database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    \n",
    "    #save gamelogs\n",
    "    df.to_sql(\"pitching_gamelogs\", conn, if_exists='append', index=False)\n",
    "    \n",
    "    #save player info\n",
    "    player_info = df[['player_id', 'name']].drop_duplicates()\n",
    "    player_info.to_sql(\"scraped_players\", conn, if_exists='append', index=False)\n",
    "    \n",
    "    # Close connection\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"{df['name'].iloc[0]} finished\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put it all together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_all_players(filepath):\n",
    "    test_ids = (pd.read_csv(filepath))[\"player_id\"]\n",
    "    for player_id in test_ids:\n",
    "        print(player_id)\n",
    "        df = await player_scrape(player_id)\n",
    "        df = cleanse_pitcher_game_logs(df)\n",
    "        save_pitcher_logs(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run it on csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply nest_asyncio to allow asyncio to run in Jupyter Notebook\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Filepath to your CSV file (update this if needed)\n",
    "csv_filepath = \"test_ids.csv\"  # Adjust if it's in a different directory\n",
    "\n",
    "# Run the async function in the event loop\n",
    "asyncio.run(scrape_all_players(csv_filepath))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
